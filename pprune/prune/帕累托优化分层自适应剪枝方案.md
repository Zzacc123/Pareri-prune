# 帕累托优化分层自适应神经元剪枝方案 (Pareto-Optimal Hierarchical Adaptive Pruning)

**“信号采集 -> 决策权衡 -> 精准执行”**

###  阶段一：神经元敏感度信号采集 (Signal Collection)

为了量化每个神经元的作用，我们追踪模型在处理不同数据时的激活状态。

*   **追踪对象**：Llama-3.1 MLP 层（SwiGLU 结构）中的中间层神经元。具体而言，我们在 `down_proj` 的输入端注册钩子（Hook），捕获 `Act(Gate(x)) * Up(x)` 的输出。
*   **双路信号**：
    *   **遗忘信号 ($F$)**：输入 `forget10` 数据集，计算神经元的平均激活幅度。高 $F$ 值表示该神经元对遗忘知识响应强烈。
    *   **保留信号 ($R$)**：输入 `retain90` 数据集，计算神经元的平均激活幅度。高 $R$ 值表示该神经元对通用知识至关重要。
*   **技术实现**：
    *   使用 **Running Mean (在线均值)** 算法在 CPU 上累计统计量，显存占用极低，支持在单卡 24GB/40GB 环境下运行 8B 模型。
    *   支持 **HuggingFace Streaming** 模式，无需下载 TB 级数据集到本地，直接流式加载。

###  阶段二：帕累托最优决策 (Pareto-Optimal Decision Making)

这是本方案的核心创新点。我们将神经元筛选建模为一个**多目标优化问题**：
1.  **最大化** 遗忘敏感度 ($F$)
2.  **最小化** 保留敏感度 ($R$)

#### 关键算法步骤：

1.  **安全区保护 (Safety Protection)**：
    *   为了防止误删对通用能力极其重要的“枢纽神经元”（如语法控制神经元），我们引入 **$\sigma$-安全阈值**。
    *   对于每一层，计算 $R$ 的均值 $\mu_R$ 和标准差 $\sigma_R$。
    *   **规则**：任何 $R > \mu_R + 3\sigma_R$ 的神经元被强制保留，不参与剪枝决策。

2.  **局部归一化 (Local Normalization)**：
    *   对未被保护的候选神经元子集进行 Min-Max 归一化，消除层间分布差异和离群点影响，将 $(F, R)$ 映射到 $[0, 1]$ 区间。

3.  **帕累托前沿构建 (Pareto Front Construction)**：
    *   在 $(F, -R)$ 空间中寻找**非支配解集 (Non-dominated Set)**。前沿上的每一个神经元都是当前“性价比”最高的选择（即在不增加保留损失的情况下，无法找到遗忘效果更好的神经元）。

4.  **膝点定位 (Knee Point Detection)**：
    *   帕累托前沿上通常包含大量神经元，我们需要一个自动化的阈值。
    *   利用 **最大弦距离法 (Max Distance to Chord)** 寻找“膝点”。该点代表了收益递减的转折点，是平衡遗忘效果与保留能力的最佳折衷位置。

### 阶段三：分层自适应剪枝执行 (Adaptive Pruning Execution)

*   **自适应阈值**：不同层的激活分布截然不同。我们不设定全局阈值，而是利用每层的“膝点”动态决定该层的剪枝比例。
*   **剪枝判据**：在前沿上，所有 $F$ 值大于等于膝点 $F$ 值的神经元将被剪除。
*   **物理移除**：采用 **结构化剪枝 (Structured Pruning)**。对于被选中的神经元索引 $i$，同时将以下权重置零：
    *   `gate_proj[i, :]` (Row)
    *   `up_proj[i, :]` (Row)
    *   `down_proj[:, i]` (Column)
    *   这等效于在物理上移除了该神经元，而不仅仅是掩盖其输出。

## 实验流程图



![图1](C:\Users\zac\Desktop\2024\笔记\LocalGraph\图1.png)

